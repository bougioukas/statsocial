# Descriptive statistics {#sec-descriptive}

```{r}
#| include: false

library(tidyverse)
library(here)
library(kableExtra)

library(fontawesome)
library(scales)
library(ggsci)
library(ggpubr)
library(MESS)
library(questionr)

library(readxl)
rses1 <- read_excel(here("data", "rses1.xlsx"))
rses1$sex <- factor(rses1$sex, labels = c("male", "female"))
rses1$Score_cat <- factor(rses1$Score_cat, levels = c("low", "medium", "high"))
```

When we have finished this chapter, we should be able to:

::: {.callout-caution icon="false"}
## `r fa("circle-dot", prefer_type = "regular", fill = "red")` Learning objectives

-   Use frequency counts and percentages to describe categorical variables.
-   Display frequency distributions for categorical variables using bar plots.
-   Use statistical measures such as mean, median, standard deviation and interquartile range to describe numerical variables.
-   Generate and assess visualizations like histograms, density plots, and box plots to understand the distribution and spread of numerical data.
:::

 

## Data

We will explore a dataset containing 258 participants (rows) and 8 variables (columns). The variables include sex (female/male), age (in years), time spent on the internet and social media (in hours), the total score (0-30) from responses to 10 questions on the Rosenberg Self-Esteem Scale ([RSES](https://socy.umd.edu/about-us/using-rosenberg-self-esteem-scale)), and the categorization of that score into three levels of self-esteem: low (0-15), medium (16-19), and high (20-30) [@garcía2019].

 

```{r}
#| echo: false
#| message: false

DT::datatable(
  rses1, extensions = 'Buttons', options = list(
    dom = 'tip'
  )
)

```

 

## Summarizing categorical data (Frequency Statistics)

### One variable frequency tables and plots

The first step in analyzing a categorical variable is to count the occurrences of each label and calculate their frequencies. This collection of frequencies for all possible categories is known as the **frequency distribution** of the variable. Additionally, we can express these frequencies as proportions of the total number of observations, which are referred to as **relative frequencies**. If we multiply these proportions by 100, we obtain **percentages** (%).

 

**Sex variable**

Let's create a a frequency table for the `sex` variable:

![Fequency table for the sex.](images/tb001.png){#fig-tb001 width="70%"}

The table displays the following:

-   **Absolute frequency (n):** The number of participants in each category (male: 109, female: 149).

-   **Percentage (%):** The proportion of participants in each category relative to the total number of participants (relative frequency) multiplied by 100% (male: 109/258 x 100 = 42.2%, female: 149/258 x 100 = 57.8%). Note that the percentages sum up to 100% (42.2% + 57.8%).

-   **Cumulative percentage (%):** The sum of the percentage contributions of all categories up to and including the current one. For example, for the male category, the cumulative percentage is 42.2%. When combining male and female categories, the cumulative percentage is 42.2% + 57.8% = 100%. Therefore, the final cumulative percentage must equal 100%.

While frequency tables are extremely useful, plotting the data often provides a clearer presentation. For categorical variables, such as sex, it is straightforward to display the number of occurrences in each category using **bar plots**. The x-axis typically represents the categories of the variable—in this case, "male" and "female". The y-axis represents the frequency or count of occurrences for each category.

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: fig-barsex1
#| fig-cap: Bar plot showing the frequency distribution of the sex.
#| fig-width: 5
#| fig-height: 4.5

# create a data frame with sex groups and their counts
dat0 <- rses1 |> 
  count(sex)

# plot the data
ggplot(dat0, aes(x = sex, y = n)) +
  geom_col(width=0.65, fill = "#0073C2") +
  geom_text(aes(label=n),
            vjust=1.6, color = "white", size = 3.5) +
  labs(x = "Sex", y = "Frequency") +
  theme_minimal(base_size = 14)
```

\vspace{15pt}

If the y-axis represents percentages (%), then each bar's height corresponds to the percentage of participants in that category. For example, the percentage of female participants is 57.8%.

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: fig-barsex2
#| fig-cap: Bar plot showing the percentage of participants for each level of self-esteem.
#| fig-width: 5
#| fig-height: 4.5


# create a data frame with self-esteem levels, their counts, and percentages
dat1 <- dat0 |> 
  mutate(pct = round_percent(n, 1))

# plot the data
ggplot(dat1, aes(x = sex, y = pct)) +
  geom_col(width=0.65, fill = "#0073C2") +
  geom_text(aes(label=paste0(pct, "%")),
            vjust=1.6, color = "white", size = 3.5) +
  labs(x = "Sex", y = "Percentage") +
  scale_y_continuous(labels = scales::percent_format(scale = 1)) +
  theme_minimal(base_size = 14)
```

 

**Score_cat variable (self-esteem)**

Similarly, we can create the frequency table for the `Score_cat` (self-esteem) variable:

![Frequency table for the levels of self-esteem.](images/tb002.png){#fig-tb002 width="70%"}

In the above table, we observe that 40.3% (104 out of 258) of participants have a low level of self-esteem. When we combine the low and medium categories, the cumulative percentage is: 40.3% + 32.6% = 72.9%. Finally, for all categories (low, medium, high), the cumulative percentage sums to 72.9% + 27.1% = 100%.

@fig-baresteem1 illustrates the frequency distribution of self-esteem. The horizontal axis (*x-axis*) displays the different self-esteem categories, ordered according to increasing self-esteem levels, while the vertical axis (y-axis) shows the frequency of each category.

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: fig-baresteem1
#| fig-cap: Bar plot showing the frequency for each level of self-esteem.
#| fig-width: 5
#| fig-height: 4.5


# create a data frame with self-esteem levels and their counts
dat2 <- rses1 |> 
  count(Score_cat)

# plot the data
ggplot(dat2, aes(x = Score_cat, y = n)) +
  geom_col(width=0.65, fill = "#0073C2") +
  geom_text(aes(label=n),
            vjust=1.6, color = "white", size = 3.5) +
  labs(x = "Self-esteem", y = "Frequency") +
  theme_minimal(base_size = 14)
```

@fig-baresteem2 illustrates the distribution of self-esteem using percentages. Most participants fall into the category of low self-esteem, accounting for 40.3% (172 out of 428), highlighting a significant portion of the sample that may benefit from targeted interventions or support.

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: fig-baresteem2
#| fig-cap: Bar plot showing the percentage of participants for each level of self-esteem.
#| fig-width: 5
#| fig-height: 4.5


# create a data frame with self-esteem levels, their counts, and percentages
dat3 <- dat2 |> 
  mutate(pct = round_percent(n, 1))

# plot the data
ggplot(dat3, aes(x = Score_cat, y = pct)) +
  geom_col(width=0.65, fill = "#0073C2") +
  geom_text(aes(label=paste0(pct, "%")),
            vjust=1.6, color = "white", size = 3.5) +
  labs(x = "Self-esteem", y = "Percentage") +
  scale_y_continuous(labels = scales::percent_format(scale = 1)) +
  theme_minimal(base_size = 14)
```

 

::: callout-important
## Tips for simple bar plots

-   All bars should have equal width and equal spacing between them.
-   The height of each bar should correspond to the data it represents.
-   The bars should be plotted against a **common zero-valued baseline**.
:::

### Two variable tables (Contingency tables) and plots

**A. Frequency contingency table**

In addition to tabulating each categorical variable separately, we might be interested in the distribution of self-esteem levels (categorized as low, medium, and high) among male and female participants in the dataset. This can be achieved by creating a frequency **contingency table**, as shown in @fig-tb0. Each cell value in the table represents the number of occurrences (frequency) corresponding to the combination of categories from the two different variables.

![Frequency contingency table which cross tabulates sex and self-esteem levels. Each cell value in the table represents the count corresponding to the combination of categories from the two variables.](images/tb0.png){#fig-tb0 width="70%"}

**Note:** The table also typically includes **row and column totals**, also known as marginal totals, that sum the counts for each row and column, respectively.

 

**B. Joint distribution contingency table**

A **joint distribution** contingency table displays both the frequency of observations across categories of two variables and the **percentage distributions** of those frequencies. The percentages are calculated by dividing the frequency in each cell by the **overall total** (258), then multiplying the result by 100. This shows the percentage of the total observations that fall into each category combination.

![Joint distribution contingency table. The percentages are calculated by dividing the frequency in each cell by the overall total.](images/tb1.png){#fig-tb1 width="75%"}

 

**C. Conditional distribution contingency table**

Suppose we are interested in the distribution of **self-esteem levels** within each sex group, meaning we are observing how self-esteem vary **among males** and **among females**. By **conditioning** on sex, we divide each cell's frequency by the corresponding **row total** (row marginal total), rather than the overall total. This method allows us to examine the **conditional distribution** of self-esteem within each sex group. For example, the percentage of participants with low self-esteem, given that the participant is female, is calculated as (78/149) x 100 ≈ 52.4%.

![Conditional distribution contingency table. The percentages are calculated by dividing the frequency in each cell by the row marginal total.](images/tb2.png){#fig-tb2 width="75%"}

This data analysis indicates notable differences in self-esteem levels between male and female participants. Specifically, the percentage of female participants with low self-esteem (52.4%) is substantially greater than that of male participants (23.9%).

::: {.callout-tip icon="false"}
## `r fa("comment", fill = "#1DC5CE")` Comment

If we are interested in the distribution of **sex** within each self-esteem level, focusing on how the proportion of males and females varies within each self-esteem category, we condition on self-esteem. This means we divide each cell's frequency by the corresponding **column total**. For example, among those with low self-esteem, the percentage of females is (78/104) x 100 ≈ 75.0%
:::

 

We can also graphically present the data in the table shown in @fig-tb2. A side-by-side bar plot (@fig-sidebar) or, preferably, a grouped bar plot (@fig-groupbar) can facilitate easier visual comparisons.

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: fig-sidebar
#| fig-cap: Side-by-side bar plot showing by self-esteem level and sex.
#| fig-width: 7
#| fig-height: 5.5

# create a data frame with ordered self-esteem levels and their counts by sex
dat4 <- rses1 |> 
  count(Score_cat, sex) |>  
  group_by(sex) |> 
  mutate(pct = round_percent(n, 1)) |> 
  ungroup()

ggplot(dat4) + 
  geom_col(aes(Score_cat, pct, fill = sex), width = 0.7, position = "dodge") +
  geom_text(aes(Score_cat, pct, label = paste0(pct, "%"), 
                group = sex), color = "white", size = 3.5, vjust=1.2,
            position = position_dodge(width = .9)) +
  labs(x = "Self-esteem", y = "Percentage") +
  scale_y_continuous(labels = scales::percent_format(scale = 1)) +
  scale_fill_jco() +
  theme_minimal(base_size = 14) +
  theme(legend.position="none",
        axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(~sex, ncol = 2)
```

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: fig-groupbar
#| fig-cap: Grouped bar plot showing by self-esteem level and sex.
#| fig-width: 8
#| fig-height: 5

ggplot(dat4) + 
  geom_col(aes(Score_cat, pct, fill = sex), width = 0.8, position = "dodge") +
  geom_text(aes(Score_cat, pct, label = paste0(pct, "%"), 
                group = sex), color = "white", size = 3.5, vjust=1.2,
            position = position_dodge(width = .9)) +
  labs(x = "Self-esteem", y = "Percentage") +
  scale_y_continuous(labels = scales::percent_format(scale = 1)) +
  scale_fill_jco() +
  theme_minimal(base_size = 14)

```

Alternatively, we can create a stacked bar plot, where the bars are segmented by self-esteem levels. @fig-stackbar illustrates a **100% stacked bar plot**, which displays the percentage of each self-esteem level (low, medium, high) among male and female participants, emphasizing the relative differences within each group. For example, the plot shows that a higher proportion of females have low self-esteem (52.4%) compared to males (23.9%), while males have a higher proportion of medium (43.1%) and high self-esteem (33%) compared to females.

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: fig-stackbar
#| fig-cap: A horizontal stacked bar plot showing the distribution of self-esteem stratified by sex.
#| fig-width: 8
#| fig-height: 2.5

# create a data frame with self-esteem levels and their counts by sex
dat5 <- rses1 |> 
  group_by(sex) |> 
  count(Score_cat) |> 
  mutate(pct = round_percent(n, 2)) |> 
  ungroup()

ggplot(dat5, aes(x = sex, y = pct, fill = forcats::fct_rev(Score_cat)))+
  geom_bar(stat = "identity", width = 0.8)+
  geom_text(aes(label = paste0(round(pct, 1), "%"), y = pct), size = 3,
            position = position_stack(vjust = 0.5)) +
  coord_flip()+
  scale_fill_simpsons() +
  scale_y_continuous(labels = scales::percent_format(scale = 1))+
  labs(x = "Sex", y = "Percentage", fill = "Self-esteem") +
  theme_minimal(base_size = 14)
```

\vspace{10pt}

::: callout-warning
## Caution

One consideration when using stacked bar plots is the number of variable levels: with many categories, stacked bar plots can become confusing.
:::

 

## Summarizing numerical data (Summary Statistics) and plots

Summary measures are **single numerical values** that summarize a set of data. Numeric data can be described using two main types of summary measures (\@tbl-measures).

1.  Measures of **central location**: These describe the "center" of the data distribution. Common examples include the mean, median, and mode.

2.  Measures of **dispersion**: These quantify the spread of values around the central value. Examples include the range, interquartile range (IQR), variance, and standard deviation.

 

| **Measures of Central Location** | **Measures of Dispersion** |
|:-----------------------------|:-----------------------------------------|
| • Mean | • Variance |
| • Median | • Standard Deviation |
| • Mode | • Range (Minimum, Maximum) |
|  | • Interquartile Range (1st and 3rd Quartiles) |

: Common summary measures of central location and dispersion {#tbl-measures}

 

Additionally, **measures of shape** such as the sample coefficients of **skewness** and **kurtosis** provide further insights by revealing the overall shape and characteristics of the distribution.

### Measures of central location

**A. Sample Mean or Average**

::: content-box-purple
The arithmetic mean, or average, denoted as $\bar{x}$, is calculated by dividing the sum of all values by the total number of values.
:::


$$\bar{x}= \frac{Sum \ of \ values}{Number \ of \ values}$$ {#eq-mean}



***Example***

We subset the data to a smaller sample to make it easier to manually calculate the summary measures. As an example, we will use the number of hours per day spent on the internet by 15-year-old females with low self-esteem, which are as follows:

$$ 5 \ \ \ \ \  4  \ \ \ \ \ 12 \ \ \ \ \  8 \ \ \ \ \  4 $$

To calculate the mean, we use the @eq-mean:

$$\bar{x} = \frac{5 + 4 + 12 + 8 + 4}{5} = \frac{33}{5} = 6.6 \ hours$$

 

Suppose we add the value of 24 to the data: $$ 5 \ \ \ \ \  4  \ \ \ \ \ 12 \ \ \ \ \  8 \ \ \ \ \  4 \ \ \ \ \  \underline{24}$$

The new mean, $\bar{x}_{new}$, is calculated as follows:

$$\bar{x}_{new}= \frac{5 + 4 + 12 + 8 + 4 + 24}{6} = \frac{57}{6} = 9.5 \ hours$$

We observe that the mean is sensitive to extreme values, such as the inclusion of 24 hours in this data (noting that 24 hours is the maximum possible in a single day). After adding this extreme value, the mean increased from 6.6 to 9.5. This significant rise of 2.9 hours illustrates how outliers can distort the average, making it less representative of the dataset.

 

::: content-box-blue
**Advantages of mean**

-   It uses all the data values in the calculation and is the balance point of the data.
-   It is algebraically defined and thus mathematically manageable.

**Disadvantages of mean**

-   It is highly influenced by the presence of **outliers**—values that are abnormally high or low—making it a non-resistant summary measure.
-   It cannot be easily determined by simply inspecting the data and is usually not equal to any of the individual values in the sample.
:::

 

**B. Median of the sample**

The **sample median**, denoted as *md*, is an alternative measure of location that is less sensitive to outliers than mean.

::: content-box-purple
The median is calculated by first sorting the observed values (i.e. arranging them in an ascending or descending order) and selecting the middle one. If the number of observations is **odd**, the median corresponds to the number in the middle of the sorted values. If the number of observations is **even**, the median is the average of the two middle numbers.
:::

***Example***

First, we sort the observed values from smallest to largest:

**Observed values:** $\ \ \ \ \ 5 \ \ \ \ \  4  \ \ \ \ \ 12 \ \ \ \ \  8 \ \ \ \ \  4$

**Sorted values:** $\ \ \ \ \ \ \ \ \  4 \ \ \ \ \  4 \ \ \ \ \ \  5 \ \ \ \ \ \  8  \ \ \ \ \ 12$

The number of observations is 5, which is an odd number; therefore, the median corresponds to the value in the middle of the sorted data:

$$ 4 \ \ \ \ \ 4 \ \ \ \ \ \textcolor{black}{\textbf{5}} \ \ \ \ \ 8 \ \ \ \ \ 12 $$

$$md = 5 \ hours$$  

Let's add the value of 24 to the data. In this case, the number of observations becomes 6, which is an even number. The new median, $md_{new}$, is the average of the two middle numbers, 5 and 8:

$$ 4 \ \ \ \ \ 4 \ \ \ \ \ \textcolor{black}{\textbf{5}} \ \ \ \ \ \textcolor{black}{\textbf{8}} \ \ \ \ \ 12 \ \ \ \ \ \underline{24}$$

$$md_{new} = \frac{5 + 8}{2} = \frac{13}{2} = 6.5 \ hours$$

We observe that the median is not strongly influenced by the addition of the extreme value of 24; the median increased from 5 to 6.5.

 

::: content-box-blue
**Advantages of median**

-   It is resistant to extreme values (outliers) compared to the mean.

-   For data measured on an ordinal scale (e.g., rankings), the median is often more meaningful than the mean.

**Disadvantages of median**

-   It ignores the actual values of the data points, potentially losing some information about the data.
:::

 

**C. Mode of the sample**

Another measure of location is the **mode** of the sample.

::: content-box-purple
Mode represents the value that occurs **most frequently** in a set of data values.
:::

***Example***

In our example, the value of 4 appears twice in the data:

$$ 5 \ \ \ \ \ \textcolor{black}{\textbf{4}} \ \ \ \ \ 12 \ \ \ \ \ 8 \ \ \ \ \ \textcolor{black}{\textbf{4}} $$

Therefore, the mode is:

$$ Mode = 4$$

It's important to note that some datasets may not have a mode if each value occurs only once. For example, if we replace one of the fours with a three:

$$ 5 \ \ \ \ \  \underline{3}  \ \ \ \ \ 12 \ \ \ \ \  8 \ \ \ \ \  4 $$ In this case, no value repeats, so the dataset has no mode.

 

However, if we replace the 12 with an 8, the dataset becomes:

$$ 5 \ \ \ \ \  \textcolor{red}{\textbf{4}}  \ \ \ \ \ \underline{\textcolor{green}{\textbf{8}}} \ \ \ \ \  \textcolor{green}{\textbf{8}} \ \ \ \ \  \textcolor{red}{\textbf{4}} $$

Here, both 4 and 8 appear twice, making the dataset bimodal, meaning it has two modes.

$$ \textcolor{red}{Mode1 = 4}$$ and

$$ \textcolor{green}{Mode2 = 8}$$

 

::: {.callout-tip icon="false"}
## `r fa("comment", fill = "#1DC5CE")` Comment

While the mode is less commonly used for numerical data, it can be a useful measure of central tendency for categorical data, representing the category with the highest frequency.
:::

 

### Measures of dispersion

**A. Range of the sample**

The **minimum (min)** value represents the lowest value observed in a dataset, while the **maximum (max)** value represents the highest value. These values provide valuable insights into the range and potential outliers within the dataset.

::: content-box-purple
In mathematics, the **range** is the difference between the maximum and minimum values in a data set.
:::

$$range = Max - Min$$ {#eq-range}


***Example***

In our example, the minimum is Min = 4 hours, and the maximum is Max = 12 hours. 

$$ \textcolor{black}{\textbf{4}} \ \ \ \ \  4 \ \ \ \ \ 5  \ \ \ \ \ 8 \ \ \ \ \ \textcolor{black}{\textbf{12}}$$

Therefore, according to @eq-range:

$$ range = 12 - 4 = 8 \ hours$$

 

Let's add the extreme value of 24 to the data.

$$ \textcolor{black}{\textbf{4}} \ \ \ \ \ 4 \ \ \ \ \ 5  \ \ \ \ \ 8 \ \ \ \ \ 12 \ \ \ \ \ \underline{\textcolor{black}{\textbf{24}}}$$ 

In this case, the range becomes:

$$range = 24 -4 = 20 \ hours$$

::: content-box-gray
The main disadvantages of the range as a measure of dispersion are its sensitivity to outliers and the fact that it uses only the extreme values, ignoring all other data points.
:::

 

**B. Inter-quartile range of the sample**

A quantile indicates the value below which a certain proportion of the data falls. The most commonly used quantiles are known as **quartiles**:

-   **$Q_1$ (lower quartile)** represents the value at which 25% of the data falls below it and 75% falls above it.

-   **$Q_2$ (median)** is the middle value when the data is arranged in ascending or descending order.

-   **$Q_3$ (upper quartile)** represents the value at which 75% of the data falls below it and 25% falls above it.

::: content-box-purple
Interquartile range is the difference between the third quartile (or upper quartile) and the first quartile (or lower quartile) in an ordered data set.
:::


$$IQR = Q_3 - Q_1$$ {#eq-iqr} 



![Quartiles and inter-quartile range.](images/iqr.png){#fig-iqr width="50%"}


It is important to note that there are numerous definitions of sample quantiles used in statistical software packages, and discussing them is beyond the scope of this introductory course [@hyndman1996]. Therefore, we will rely on the results provided by Jamovi.


***Example***

In our example, the first quartile is $Q_1 = 4$ hours, and the third quartile is $Q_3 = 8$ hours.

$$ 4 \ \ \ \ \  \textcolor{black}{\textbf{4}} \ \ \ \ \ 5  \ \ \ \ \ \textcolor{black}{\textbf{8}} \ \ \ \ \ 12$$

Therefore, the inter-quartile range is:

$$IQR = Q_3 - Q1 = 8 - 4 = 4$$

 

After adding an extreme value such as 24, our example dataset is as follows: 

$$ 4 \ \ \ \ \ 4 \ \ \ \ \ 5  \ \ \ \ \ 8 \ \ \ \ \ 12 \ \ \ \ \ \underline{24}$$ 


We would expect $Q_1$ to have a value between 4 and 5, and $Q_3$ to fall between 8 and 12. JAMOVI provides $Q_1 = 4.25$ hours, and $Q_3 =11$ hours. Therefore, the new inter-quartile range is:

$$IQR_{new} = Q_3 - Q1 = 11 - 4.25 = 6.75$$


::: content-box-gray

As with the range, greater variability in the data typically leads to a larger IQR. However, unlike the range, the **IQR is resistant to outliers**, as it is not influenced by observations below the first quartile or above the third quartile.
:::

 

**C. Sample variance**

Sample variance, denoted as $s^2$, is a measure of spread of the data based on the **deviations** of the data values from the mean. However, when we average these deviations, the sum always equals zero. This occurs because the mean acts as a balance point where the total positive and negative deviations cancel each other out. To resolve this issue, we calculate the variance using **squared deviations**, which ensures that all values contribute positively to the measure of spread.


::: content-box-purple

Mathematically, the sample variance, $s^2$, is calculated as the sum of the squared deviations from the sample mean, divided by the number of observations minus 1.
:::


$$s^2 = \frac{\text{Sum of squared deviations}}{\text{Number of values} - 1}$$ {#eq-var} 



***Example***

The original values are:

$$ 5 \ \ \ \ \  4  \ \ \ \ \ 12 \ \ \ \ \  8 \ \ \ \ \  4 $$

and we have calculated the mean, $\bar{x} = 6.6$. The deviation from the mean for the first value is calculated as 5 - 6.6 = -1.6, and for the second value, it is 4 - 6.6 = -2.6, and so on.


Thus, according to @eq-var:

$$
\begin{align*}
s^2 &= \frac{(5 - 6.6)^2 + (4 - 6.6)^2 + (12 - 6.6)^2 + (8 - 6.6)^2 + (4 - 6.6)^2}{5 - 1} \\
    &= \frac{(-1.6)^2 + (-2.6)^2 + (5.4)^2 + (1.4)^2 + (-2.6)^2}{4} \\
    &= \frac{2.56 + 6.76 + 29.16 + 1.96 + 6.76}{4} \\
    &= \frac{47.20}{4} \\
    &= 11.80 \ hours^2
\end{align*}
$$

 

After adding 24 to the data, the new mean is $\bar{x}_{new} = 9.5$, and the variance is calculated as follows:

$$
\begin{align*}
s^2 &= \frac{(5 - 9.5)^2 + (4 - 9.5)^2 + (12 - 9.5)^2 + (8 - 9.5)^2 + (4 - 9.5)^2 + (24 - 9.5)^2}{6 - 1} \\
    &= \frac{(-4.5)^2 + (-5.5)^2 + (2.5)^2 + (-1.5)^2 + (-5.5)^2 + (14.5)^2}{5} \\
    &= \frac{20.25 + 30.25 + 6.25 + 2.25 + 30.25 + 210.25}{5} \\
    &= \frac{299.5}{5} \\
    &= 59.9 \ hours^2
\end{align*}
$$


The variance, being expressed in square units, is not the preferred metric for describing the variability of data.

 

**D. Standard deviation of the sample**

Standard deviation is a typical distance of observations from the mean.


::: content-box-purple

Standard deviation, denoted as *s* or *sd*, represents the typical distance of observations from the mean. It is calculated as the square root of the sample variance.

:::


$$s = \sqrt{s^2}$$ {#eq-sd} 



***Example***
 
The standard deviation is:

$$s = \sqrt{11.8} = 3.44 \ hours$$

and is expressed in the same units as the original data values.

 

With the addition of the value 25, the standard deviation becomes:

$$s = \sqrt{59.9} = 7.74 \ hours$$

::: content-box-gray

The standard deviation uses all observations in a dataset for its calculation and is expressed in the same units as the original data. However, it is sensitive to outliers, which can substantially  influence its value.

:::

